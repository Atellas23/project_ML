---
title: "wine project"
author: "Ã€lex, Luis, Aleix"
date: "25/4/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
library(dplyr)
library(klaR)
library(magrittr)
library(caret)
```



```{r}
our_seed <- 46290
red_w <- read.table("winequality-red.csv", sep=';', header = TRUE)
white_w <- read.table("winequality-white.csv", sep=';', header = TRUE)
```


```{r}
head(red_w)
dim(red_w)
head(white_w)
dim(white_w)
```

```{r}
red_w <- distinct(red_w)
white_w <- distinct(white_w)

wine <- rbind(red_w, white_w)

red_w <- red_w[c(-723,-964),]
white_w <- white_w[c(-2175, -2765),]
wine <- wine[c(-723,-964),]
```

```{r}
apply(red_w, 2, hist)
```

```{r}
wine <- rbind(red_w, white_w)
wine$type <- c(rep('r', nrow(red_w)), rep('w', nrow(white_w)))
wine.quality <- wine$quality
wine.data <- subset(wine, select = 1:11)
```


Separate data into test and training
```{r}
# Randomly separate into learning data and test data
set.seed(our_seed)
sample_size <- floor(2/3 * nrow(wine))
training_indices <- sample(seq_len(nrow(wine)), size = sample_size)
training.data  <- wine[training_indices, ]
testing.data <- wine[-training_indices, ]
```

## TYPE PREDICTION
```{r}

cv.lda <-
  function (data, model=origin~., yname="origin", K=10, seed=123) {
    n <- nrow(data)
    set.seed(seed)
    datay=data[,yname] #response variable
    library(MASS)
    #partition the data into K subsets
    f <- ceiling(n/K)
    s <- sample(rep(1:K, f), n)  
    #generate indices 1:10 and sample n of them  
    # K fold cross-validated error
    
    CV=NULL
    
    for (i in 1:K) { #i=1
      test.index <- seq_len(n)[(s == i)] #test data
      train.index <- seq_len(n)[(s != i)] #training data
      
      #model with training data
      lda.fit=lda(model, data=data[train.index,])
      #observed test set y
      lda.y <- data[test.index, yname]
      #predicted test set y
      lda.predy=predict(lda.fit, data[test.index,])$class
      
      #observed - predicted on test data
      error= mean(lda.y!=lda.predy)
      #error rates 
      CV=c(CV,error)
    }
    #Output
    list(call = model, K = K, 
         lda_error_rate = mean(CV), seed = seed)  
  }

lda.kfcv <- function(target, dd, nfolds = 10) {
  cat("This function calculates the K-fold CV error of LDA,\nusing all present variables except for the target.\n")
  set.seed(46290)
  rownames(target) <- NULL
  rownames(dd) <- NULL
  n <- nrow(dd)
  folds <- createFolds(seq_len(n), k = nfolds, list = TRUE)
  cv.err <- NULL
  for (fold in folds) {
    adj.data <- dd[-fold,]
    val <- dd[fold,]
    fmla <- as.formula(paste(target,"~."))
    lda.pred <- lda(fmla, data = adj.data) %>% predict(newdata = val)
    predicted.class <- lda.pred$class
    # print(val[target])
    # print(length(lda.pred$class))
    tab <- table(Truth = val[,target], Preds = predicted.class)
    cv.err <- c(cv.err, 1 - sum(tab[row(tab)==col(tab)])/sum(tab))
  }
  cv.err <- mean(cv.err)
}

cosa <- lda.kfcv("type", training.data, nfolds = 3)


lda.model <- lda(type ~ .-quality, data = wine)
loadings.lda <- as.matrix(wine.data) %*% as.matrix(lda.model$scaling)
plot(loadings.lda, col=c(rep(2, nrow(red_w)), rep(4, nrow(white_w))), ylab = "Projected coordinates", main = "LDA projection")
```


```{r}
N <- nrow(wine)
neighbours <- 1:sqrt(N)

loop.k <- function(mydata, mytargets, myneighbours)
{
  errors <- matrix(nrow=length(myneighbours), ncol=2)
  colnames(errors) <- c("k","LOOCV error")

  for (k in myneighbours)
  {
    myknn.cv <- knn.cv(mydata, mytargets, k = myneighbours[k])
  
    # fill in number of neighbours and LOOCV error
    errors[k, "k"] <- myneighbours[k]
  
    tab <- table(Truth=mytargets, Preds=myknn.cv)
    errors[k, "LOOCV error"] <- 1 - sum(tab[row(tab)==col(tab)])/sum(tab)
  }
  errors
}
```

```{r}
set.seed(our_seed)
loocv.error <- loop.k(wine.data, wine$type, neighbours)
plot(loocv.error, type="l", xaxt = "n")
axis(1, neighbours)
kmin <- which.min(loocv.error[,2])
loocv.error[kmin,]
```


```{r}
set.seed(our_seed)
loocv.error <- loop.k(scale(wine.data), wine$type, neighbours)
plot(loocv.error, type="l", xaxt = "n")
axis(1, neighbours)
kmin <- which.min(loocv.error[,2])
loocv.error[kmin,]
```

```{r}
set.seed(our_seed)
loocv.error.lda <- loop.k(loadings.lda, wine$type, neighbours)
plot(loocv.error.lda, type='l')#, xaxt='n')
kmin <- which.min(loocv.error.lda[,2])
loocv.error.lda[kmin,]
```


```{r}
set.seed(our_seed)
lda.model.loocv <- lda(x=wine.data, grouping=wine$type, CV=TRUE)
(ct <- table(Truth=wine$type, Pred=lda.model.loocv$class))
1 - sum(ct[row(ct)==col(ct)])/sum(ct)
```

```{r}
set.seed(our_seed)
qda.model.loocv <- qda(x=wine.data, grouping=wine$type, CV=TRUE)
(ct <- table(Truth=wine$type, Pred=qda.model.loocv$class))
1 - sum(ct[row(ct)==col(ct)])/sum(ct)
```


```{r}
set.seed(our_seed)
rda.model.loocv <- rda(x=wine.data, grouping=wine$type, fold=nrow(wine.data))
rda.model.loocv$regularization
```
We can see how lambda is 1 and gamma is very close to zero, so we should use LDA.


#### GLM
```{r}
set.seed(our_seed)
learning.data$type <- factor(learning.data$type)
# We use LOOCV, so we will use nrow(wine.data) folds
k <- nrow(wine.data)
glm_model <- train(form = type ~ .-quality,
               data = learning.data,
               trControl = trainControl(method = "cv", number = k),
               method = "glm",
               family = "binomial")

# Table of results along with accuracy
table(learning.data$type, predict(glm_model))
glm_model

# Real accuracy as calculated over test data
glm_predicted <- glm_model %>% predict(test.data, type = "raw")
(glm_table <- table(test.data$type, glm_predicted))
(glm_error <- 1 - sum(glm_table[row(glm_table)==col(glm_table)])/sum(glm_table))
```

## QUALITY PREDICTION

### Regression
```{r}
set.seed(our_seed)
# We use LOOCV, so we will use nrow(wine.data) folds
k <- nrow(wine.data)
learning.data$type <- as.factor(learning.data$type)
test.data$type <- as.factor(test.data$type)
quality.glm.model <- train(form = quality ~ .,
               data = learning.data,
               trControl = trainControl(method = "cv", number = k),
               method = "lm")

# Table of results along with accuracy
table(Truth=learning.data$quality, Pred=round(predict(quality.glm.model)))
quality.glm.model

# Real accuracy as calculated over test data
glm.predicted <- quality.glm.model %>% predict(test.data, type = "raw")
glm.predicted <- round(glm.predicted)
(glm.table <- table(Truth=test.data$quality, Pred=glm.predicted))
(glm.error <- 1 - sum(glm.table[row(glm.table)==col(glm.table)])/sum(glm.table))
```
#### Ridge
#### LASSO

### Classification

